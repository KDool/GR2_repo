{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G edges:  7375\n",
      "G nodes:  9498\n"
     ]
    }
   ],
   "source": [
    "# Create Graph From file SNN_metric\n",
    "import create_snnGraph as cs\n",
    "import networkx as nx\n",
    "import sparsify_snnGraph as ss\n",
    "\n",
    "a = cs.readData('../snn_computation/snn_metric.csv')\n",
    "# a = cs.readData('../../SNN-density/snn_computation/snn_metric_ds2.csv')\n",
    "G = cs.createGraph(a)\n",
    "\n",
    "print(\"G edges: \",G.number_of_edges())\n",
    "print(\"G nodes: \",G.number_of_nodes())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhoutte Coefficient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from Evaluation.silhouette_coefficient import silhoutte_result\n",
    "def read_snnArray(file_path=None):\n",
    "    df = pd.read_csv(file_path,index_col=False,header=None,sep=' ')\n",
    "    snn_nparray = np.array(df)\n",
    "    return snn_nparray\n",
    "snn_nparray = read_snnArray('../snn_computation/snn_distance_metric.csv')\n",
    "# snn_nparray2 = read_snnArray('../../SNN-density/snn_computation/snn_distance_metric_ds2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo(G:nx.Graph,distance_metrix,threshold,n):\n",
    "    G1 =  G.copy()\n",
    "    snn_nparray = distance_metrix\n",
    "    label_dictionary = {}\n",
    "    for j in range (G.number_of_nodes()):\n",
    "        label_dictionary[j]=-1\n",
    "    # Sparsify Graph\n",
    "    g = ss.sparsifyGraph(G1,threshold=threshold)\n",
    "    sub_graphs = nx.connected_components(g)\n",
    "\n",
    "    # Create labels for all nodes ,  label -1 for outlier\n",
    "    i = 0\n",
    "    for sub in sub_graphs:\n",
    "        if(len(sub)>n):\n",
    "            # print(i)\n",
    "            # print(sub)\n",
    "            for node in sub:\n",
    "                label_dictionary[node]=i \n",
    "            i +=1\n",
    "    labels = list(label_dictionary.values())\n",
    "\n",
    "# Remove outliers\n",
    "\n",
    "    l = np.array(labels)\n",
    "    count = 0\n",
    "    for item in l:\n",
    "        if item>-1:\n",
    "            count = count+1\n",
    "    new_distance_metric = np.zeros((count,count),dtype=float)\n",
    "    new_distance_metric.shape\n",
    "    dictionary_no_outliers = {i:label_dictionary[i] for i in label_dictionary if label_dictionary[i]!=-1}\n",
    "\n",
    "    k = dictionary_no_outliers.keys()\n",
    "    \n",
    "    # Create a new name for each node after remove outliers\n",
    "    change_name_list={}\n",
    "    start = 0\n",
    "    for item in k:\n",
    "        change_name_list[start] = item\n",
    "        start = start+1\n",
    "\n",
    "    #Add value to new snn_array, to use for calculate  Silhoutte - after remove outliers\n",
    "    i=0\n",
    "    j=0\n",
    "    for i in range(0,count):\n",
    "        for j in range(i+1,count):\n",
    "            new_distance_metric[i][j] = snn_nparray[change_name_list[i]][change_name_list[j]]\n",
    "            new_distance_metric[j][i] = new_distance_metric[i][j]\n",
    "     # Silhoutte \n",
    "    new_label = list(dictionary_no_outliers.values())\n",
    "    number_of_cluster = len(set(new_label)) \n",
    "    if len(set(new_label)) > 1:\n",
    "        silhoute_removeouliers= silhoutte_result(new_distance_metric,new_label)\n",
    "    else:\n",
    "        print(\"Number of labels needs to > 1. ERROR!!\")\n",
    "        silhoute_removeouliers = -1\n",
    "\n",
    "    return silhoute_removeouliers,len(new_label),number_of_cluster,label_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold:  1 score: 0.022828595481381782 points: 4704 clusters: 509\n",
      "Threshold:  2 score: 0.09639488660281718 points: 2014 clusters: 576\n",
      "Threshold:  3 score: 0.20145674999047672 points: 838 clusters: 272\n",
      "Threshold:  4 score: 0.34814728315897353 points: 426 clusters: 145\n",
      "Threshold:  5 score: 0.46860608827862343 points: 293 clusters: 96\n",
      "Threshold:  6 score: 0.5216897677942888 points: 248 clusters: 78\n",
      "Threshold:  7 score: 0.5437769251459266 points: 227 clusters: 68\n",
      "Threshold:  8 score: 0.5742705145674987 points: 210 clusters: 61\n",
      "Threshold:  9 score: 0.5918509261529006 points: 196 clusters: 55\n",
      "Threshold:  10 score: 0.6394588041227534 points: 181 clusters: 52\n",
      "Threshold:  11 score: 0.6568614967365756 points: 167 clusters: 46\n",
      "Threshold:  12 score: 0.6664600668535048 points: 157 clusters: 42\n",
      "Threshold:  13 score: 0.691094855222317 points: 144 clusters: 38\n",
      "Threshold:  14 score: 0.7189566755760081 points: 135 clusters: 36\n",
      "Threshold:  15 score: 0.7550900773252771 points: 120 clusters: 32\n",
      "Threshold:  16 score: 0.7200716907872788 points: 112 clusters: 30\n",
      "Threshold:  17 score: 0.7691852630026038 points: 103 clusters: 27\n",
      "Threshold:  18 score: 0.756106650555935 points: 93 clusters: 24\n",
      "Threshold:  19 score: 0.7932184353004214 points: 72 clusters: 20\n",
      "Number of labels needs to > 1. ERROR!!\n",
      "Threshold:  20 score: -1 points: 0 clusters: 0\n",
      "Number of labels needs to > 1. ERROR!!\n",
      "Threshold:  21 score: -1 points: 0 clusters: 0\n",
      "Number of labels needs to > 1. ERROR!!\n",
      "Threshold:  22 score: -1 points: 0 clusters: 0\n",
      "Number of labels needs to > 1. ERROR!!\n",
      "Threshold:  23 score: -1 points: 0 clusters: 0\n",
      "Number of labels needs to > 1. ERROR!!\n",
      "Threshold:  24 score: -1 points: 0 clusters: 0\n",
      "Number of labels needs to > 1. ERROR!!\n",
      "Threshold:  25 score: -1 points: 0 clusters: 0\n",
      "Number of labels needs to > 1. ERROR!!\n",
      "Threshold:  26 score: -1 points: 0 clusters: 0\n",
      "Number of labels needs to > 1. ERROR!!\n",
      "Threshold:  27 score: -1 points: 0 clusters: 0\n",
      "Number of labels needs to > 1. ERROR!!\n",
      "Threshold:  28 score: -1 points: 0 clusters: 0\n",
      "Number of labels needs to > 1. ERROR!!\n",
      "Threshold:  29 score: -1 points: 0 clusters: 0\n"
     ]
    }
   ],
   "source": [
    "threshold_list = [i for i in range (1,30)]\n",
    "for item in threshold_list:\n",
    "    x1,x2,x3,x4 = demo(G,snn_nparray,item,1)\n",
    "    print('Threshold: ',item,'score:',x1,'points:', x2,'clusters:', x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster:  0\n",
      "[1257, 1266, 1319, 7770, 7777, 7796, 7802, 7803, 7812, 7827, 7830, 7833, 7834, 7847, 7856, 7858, 7872, 7875]\n",
      "Cluster:  1\n",
      "[1430, 7644]\n",
      "Cluster:  2\n",
      "[3341, 3407, 3454]\n",
      "Cluster:  3\n",
      "[3679, 3740]\n",
      "Cluster:  4\n",
      "[3811, 4826]\n",
      "Cluster:  5\n",
      "[3852, 4783]\n",
      "Cluster:  6\n",
      "[4407, 9497]\n",
      "Cluster:  7\n",
      "[5557, 5562]\n",
      "Cluster:  8\n",
      "[5792, 5816]\n",
      "Cluster:  9\n",
      "[6007, 6027, 6099, 6129, 8261, 8295]\n",
      "Cluster:  10\n",
      "[6110, 6211, 6292]\n",
      "Cluster:  11\n",
      "[6497, 6504, 6529]\n",
      "Cluster:  12\n",
      "[6582, 6594]\n",
      "Cluster:  13\n",
      "[6698, 6703, 6712, 6750, 6774, 6776, 8990]\n",
      "Cluster:  14\n",
      "[6823, 8059]\n",
      "Cluster:  15\n",
      "[7748, 7757]\n",
      "Cluster:  16\n",
      "[8340, 8357]\n",
      "Cluster:  17\n",
      "[8400, 8432, 8435, 8462, 8558]\n",
      "Cluster:  18\n",
      "[8864, 8878, 8905]\n",
      "Cluster:  19\n",
      "[9201, 9218]\n"
     ]
    }
   ],
   "source": [
    "x1,x2,x3,x4 = demo(G,snn_nparray,19,1)\n",
    "from collections import defaultdict\n",
    "v = defaultdict(list)\n",
    "\n",
    "for key, value in sorted(x4.items()):\n",
    "    v[value].append(key)\n",
    "for key in v.keys():\n",
    "    if (key!=-1):\n",
    "        print(\"Cluster: \",key)\n",
    "        nodes = v[key]\n",
    "        print(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of shared neighbors between  1257 1266  is: 19\n",
      "[7812, 7827, 1430, 7830, 9497, 7833, 7834, 1319, 7847, 7856, 7858, 7872, 7875, 7748, 7770, 7777, 7796, 7802, 7803]\n",
      "number of shared neighbors between  1257 7872  is: 19\n",
      "[7812, 7827, 1430, 7830, 9497, 7833, 7834, 1319, 7847, 7856, 7858, 7875, 7748, 7770, 7777, 1266, 7796, 7802, 7803]\n"
     ]
    }
   ],
   "source": [
    "# Function to count How many nodes that every items in a list shared as neighbors\n",
    "from functools import reduce\n",
    "\n",
    "def count_sharing_nodes(input_list:list,path_knn=''):\n",
    "    count = 0\n",
    "    size = len(input_list)\n",
    "    \n",
    "    list_of_list = list()\n",
    "    df = pd.read_csv(path_knn,header=None,sep=' ')\n",
    "    # df = df.drop(['Unnamed: 0'], axis=1)\n",
    "    # print(df)\n",
    "    for node in input_list:\n",
    "        temp_list = df.loc[node].values.tolist()\n",
    "        list_of_list.append(temp_list)\n",
    "    # print(list_of_list)\n",
    "    res = list(set.intersection(*map(set, list_of_list)))\n",
    "    return res\n",
    "# a=[1257, 1266, 1319, 7770, 7777, 7796, 7802, 7803, 7812, 7827, 7830, 7833, 7834, 7847, 7856, 7858, 7872, 7875]\n",
    "b = [1257, 1266]\n",
    "res = count_sharing_nodes(b,'../knn_metrics/knn_metric.csv')\n",
    "print(\"number of shared neighbors between \",b[0],b[1],' is:',len(res))\n",
    "print(res)\n",
    "\n",
    "c = [1257, 7872]\n",
    "res = count_sharing_nodes(c,'../knn_metrics/knn_metric.csv')\n",
    "print(\"number of shared neighbors between \",c[0],c[1],' is:',len(res))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
