{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G edges:  7375\n",
      "G nodes:  9498\n"
     ]
    }
   ],
   "source": [
    "# Create Graph From file SNN_metric\n",
    "import create_snnGraph as cs\n",
    "import networkx as nx\n",
    "import sparsify_snnGraph as ss\n",
    "\n",
    "a = cs.readData('../snn_computation/snn_metric.csv')\n",
    "# a = cs.readData('../../SNN-density/snn_computation/snn_metric_ds2.csv')\n",
    "G = cs.createGraph(a)\n",
    "\n",
    "print(\"G edges: \",G.number_of_edges())\n",
    "print(\"G nodes: \",G.number_of_nodes())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhoutte Coefficient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from Evaluation.silhouette_coefficient import silhoutte_result\n",
    "def read_snnArray(file_path=None):\n",
    "    df = pd.read_csv(file_path,index_col=False,header=None,sep=' ')\n",
    "    snn_nparray = np.array(df)\n",
    "    return snn_nparray\n",
    "snn_nparray = read_snnArray('../snn_computation/snn_distance_metric.csv')\n",
    "# snn_nparray2 = read_snnArray('../../SNN-density/snn_computation/snn_distance_metric_ds2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo(G:nx.Graph,distance_metrix,threshold,n):\n",
    "    G1 =  G.copy()\n",
    "    snn_nparray = distance_metrix\n",
    "    label_dictionary = {}\n",
    "    for j in range (G.number_of_nodes()):\n",
    "        label_dictionary[j]=-1\n",
    "    # Sparsify Graph\n",
    "    g = ss.sparsifyGraph(G1,threshold=threshold)\n",
    "    sub_graphs = nx.connected_components(g)\n",
    "\n",
    "    # Create labels for all nodes ,  label -1 for outlier\n",
    "    i = 0\n",
    "    for sub in sub_graphs:\n",
    "        if(len(sub)>n):\n",
    "            # print(i)\n",
    "            # print(sub)\n",
    "            for node in sub:\n",
    "                label_dictionary[node]=i \n",
    "            i +=1\n",
    "    labels = list(label_dictionary.values())\n",
    "\n",
    "# Remove outliers\n",
    "\n",
    "    l = np.array(labels)\n",
    "    count = 0\n",
    "    for item in l:\n",
    "        if item>-1:\n",
    "            count = count+1\n",
    "    new_distance_metric = np.zeros((count,count),dtype=float)\n",
    "    new_distance_metric.shape\n",
    "    dictionary_no_outliers = {i:label_dictionary[i] for i in label_dictionary if label_dictionary[i]!=-1}\n",
    "\n",
    "    k = dictionary_no_outliers.keys()\n",
    "    \n",
    "    # Create a new name for each node after remove outliers\n",
    "    change_name_list={}\n",
    "    start = 0\n",
    "    for item in k:\n",
    "        change_name_list[start] = item\n",
    "        start = start+1\n",
    "\n",
    "    #Add value to new snn_array, to use for calculate  Silhoutte - after remove outliers\n",
    "    i=0\n",
    "    j=0\n",
    "    for i in range(0,count):\n",
    "        for j in range(i+1,count):\n",
    "            new_distance_metric[i][j] = snn_nparray[change_name_list[i]][change_name_list[j]]\n",
    "            new_distance_metric[j][i] = new_distance_metric[i][j]\n",
    "     # Silhoutte \n",
    "    new_label = list(dictionary_no_outliers.values())\n",
    "    number_of_cluster = len(set(new_label)) \n",
    "    if len(set(new_label)) > 1:\n",
    "        silhoute_removeouliers= silhoutte_result(new_distance_metric,new_label)\n",
    "    else:\n",
    "        print(\"Number of labels needs to > 1. ERROR!!\")\n",
    "        silhoute_removeouliers = -1\n",
    "\n",
    "    return silhoute_removeouliers,len(new_label),number_of_cluster,label_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.022828595481381782 4704 509\n",
      "2 0.09639488660281718 2014 576\n",
      "3 0.20145674999047672 838 272\n",
      "4 0.34814728315897353 426 145\n",
      "5 0.46860608827862343 293 96\n",
      "6 0.5216897677942888 248 78\n",
      "7 0.5437769251459266 227 68\n",
      "8 0.5742705145674987 210 61\n",
      "9 0.5918509261529006 196 55\n",
      "10 0.6394588041227534 181 52\n",
      "11 0.6568614967365756 167 46\n",
      "12 0.6664600668535048 157 42\n",
      "13 0.691094855222317 144 38\n",
      "14 0.7189566755760081 135 36\n",
      "15 0.7550900773252771 120 32\n",
      "16 0.7200716907872788 112 30\n",
      "17 0.7691852630026038 103 27\n",
      "18 0.756106650555935 93 24\n",
      "19 0.7932184353004214 72 20\n",
      "Number of labels needs to > 1. ERROR!!\n",
      "20 -1 0 0\n",
      "Number of labels needs to > 1. ERROR!!\n",
      "21 -1 0 0\n",
      "Number of labels needs to > 1. ERROR!!\n",
      "22 -1 0 0\n",
      "Number of labels needs to > 1. ERROR!!\n",
      "23 -1 0 0\n",
      "Number of labels needs to > 1. ERROR!!\n",
      "24 -1 0 0\n",
      "Number of labels needs to > 1. ERROR!!\n",
      "25 -1 0 0\n",
      "Number of labels needs to > 1. ERROR!!\n",
      "26 -1 0 0\n",
      "Number of labels needs to > 1. ERROR!!\n",
      "27 -1 0 0\n",
      "Number of labels needs to > 1. ERROR!!\n",
      "28 -1 0 0\n",
      "Number of labels needs to > 1. ERROR!!\n",
      "29 -1 0 0\n"
     ]
    }
   ],
   "source": [
    "threshold_list = [i for i in range (1,30)]\n",
    "for item in threshold_list:\n",
    "    x1,x2,x3,x4 = demo(G,snn_nparray,item,1)\n",
    "    print(item,x1, x2, x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster:  0\n",
      "[1257, 1266, 1319, 7770, 7777, 7796, 7802, 7803, 7812, 7827, 7830, 7833, 7834, 7847, 7856, 7858, 7872, 7875]\n",
      "Cluster:  1\n",
      "[1430, 7644]\n",
      "Cluster:  2\n",
      "[3341, 3407, 3454]\n",
      "Cluster:  3\n",
      "[3679, 3740]\n",
      "Cluster:  4\n",
      "[3811, 4826]\n",
      "Cluster:  5\n",
      "[3852, 4783]\n",
      "Cluster:  6\n",
      "[4407, 9497]\n",
      "Cluster:  7\n",
      "[5557, 5562]\n",
      "Cluster:  8\n",
      "[5792, 5816]\n",
      "Cluster:  9\n",
      "[6007, 6027, 6099, 6129, 8261, 8295]\n",
      "Cluster:  10\n",
      "[6110, 6211, 6292]\n",
      "Cluster:  11\n",
      "[6497, 6504, 6529]\n",
      "Cluster:  12\n",
      "[6582, 6594]\n",
      "Cluster:  13\n",
      "[6698, 6703, 6712, 6750, 6774, 6776, 8990]\n",
      "Cluster:  14\n",
      "[6823, 8059]\n",
      "Cluster:  15\n",
      "[7748, 7757]\n",
      "Cluster:  16\n",
      "[8340, 8357]\n",
      "Cluster:  17\n",
      "[8400, 8432, 8435, 8462, 8558]\n",
      "Cluster:  18\n",
      "[8864, 8878, 8905]\n",
      "Cluster:  19\n",
      "[9201, 9218]\n"
     ]
    }
   ],
   "source": [
    "x1,x2,x3,x4 = demo(G,snn_nparray,19,1)\n",
    "from collections import defaultdict\n",
    "v = defaultdict(list)\n",
    "\n",
    "for key, value in sorted(x4.items()):\n",
    "    v[value].append(key)\n",
    "for key in v.keys():\n",
    "    if (key!=-1):\n",
    "        print(\"Cluster: \",key)\n",
    "        nodes = v[key]\n",
    "        print(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of shared neighbors:  18\n",
      "[6208, 6529, 8261, 8967, 8295, 6504, 6027, 9356, 1164, 6606, 6129, 6099, 6582, 6007, 3257, 3740, 253, 3679]\n"
     ]
    }
   ],
   "source": [
    "# Function to count How many nodes that every items in a list shared as neighbors\n",
    "from functools import reduce\n",
    "\n",
    "def count_sharing_nodes(input_list:list,path_knn=''):\n",
    "    count = 0\n",
    "    size = len(input_list)\n",
    "    \n",
    "    list_of_list = list()\n",
    "    df = pd.read_csv(path_knn,header=None,sep=' ')\n",
    "    for node in input_list:\n",
    "        temp_list = df.loc[node].values.tolist()\n",
    "        list_of_list.append(temp_list)\n",
    "    # print(list_of_list)\n",
    "    res = list(set.intersection(*map(set, list_of_list)))\n",
    "    return res\n",
    "# a=[1257, 1266, 1319, 7770, 7777, 7796, 7802, 7803, 7812, 7827, 7830, 7833, 7834, 7847, 7856, 7858, 7872, 7875]\n",
    "b = [3341, 3407, 3454]\n",
    "res = count_sharing_nodes(b,'../knn_metrics/knn_metric.csv')\n",
    "print(\"number of shared neighbors: \",len(res))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
